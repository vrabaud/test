/* Auto-generated by genmsg_cpp for file /home/ckilner/ros/stacks/common_msgs/sensor_msgs/msg/CameraInfo.msg */
#ifndef SENSOR_MSGS_MESSAGE_CAMERAINFO_H
#define SENSOR_MSGS_MESSAGE_CAMERAINFO_H
#include <string>
#include <vector>
#include <ostream>
#include "ros/serialization.h"
#include "ros/builtin_message_traits.h"
#include "ros/message_operations.h"
#include "ros/message.h"
#include "ros/time.h"

#include "roslib/Header.h"
#include "sensor_msgs/RegionOfInterest.h"

namespace sensor_msgs
{
template <class ContainerAllocator>
struct CameraInfo_ : public ros::Message
{
  typedef CameraInfo_<ContainerAllocator> Type;

  CameraInfo_()
  : header()
  , height(0)
  , width(0)
  , roi()
  , D()
  , K()
  , R()
  , P()
  {
    D.assign(0.0);
    K.assign(0.0);
    R.assign(0.0);
    P.assign(0.0);
  }

  CameraInfo_(const ContainerAllocator& _alloc)
  : header(_alloc)
  , height(0)
  , width(0)
  , roi(_alloc)
  , D()
  , K()
  , R()
  , P()
  {
    D.assign(0.0);
    K.assign(0.0);
    R.assign(0.0);
    P.assign(0.0);
  }

  typedef  ::roslib::Header_<ContainerAllocator>  _header_type;
   ::roslib::Header_<ContainerAllocator>  header;

  typedef uint32_t _height_type;
  uint32_t height;

  typedef uint32_t _width_type;
  uint32_t width;

  typedef  ::sensor_msgs::RegionOfInterest_<ContainerAllocator>  _roi_type;
   ::sensor_msgs::RegionOfInterest_<ContainerAllocator>  roi;

  typedef boost::array<double, 5>  _D_type;
  boost::array<double, 5>  D;

  typedef boost::array<double, 9>  _K_type;
  boost::array<double, 9>  K;

  typedef boost::array<double, 9>  _R_type;
  boost::array<double, 9>  R;

  typedef boost::array<double, 12>  _P_type;
  boost::array<double, 12>  P;


  ROSCPP_DEPRECATED uint32_t get_D_size() const { return (uint32_t)D.size(); }
  ROSCPP_DEPRECATED uint32_t get_K_size() const { return (uint32_t)K.size(); }
  ROSCPP_DEPRECATED uint32_t get_R_size() const { return (uint32_t)R.size(); }
  ROSCPP_DEPRECATED uint32_t get_P_size() const { return (uint32_t)P.size(); }
private:
  static const char* __s_getDataType_() { return "sensor_msgs/CameraInfo"; }
public:
  ROSCPP_DEPRECATED static const std::string __s_getDataType() { return __s_getDataType_(); }

  ROSCPP_DEPRECATED const std::string __getDataType() const { return __s_getDataType_(); }

private:
  static const char* __s_getMD5Sum_() { return "1b5cf7f984c229b6141ceb3a955aa18f"; }
public:
  ROSCPP_DEPRECATED static const std::string __s_getMD5Sum() { return __s_getMD5Sum_(); }

  ROSCPP_DEPRECATED const std::string __getMD5Sum() const { return __s_getMD5Sum_(); }

private:
  static const char* __s_getMessageDefinition_() { return "# This message defines meta information for a camera. It should be in a\n\
# camera namespace and accompanied by up to 5 image topics named:\n\
# \n\
# image_raw, image, image_color, image_rect, and image_rect_color\n\
#\n\
# The meaning of the camera parameters are described in detail at\n\
# http://pr.willowgarage.com/wiki/camera_calibration.\n\
\n\
##########################\n\
# Image acquisition info #\n\
##########################\n\
\n\
# Time of image acquisition, camera coordinate frame ID\n\
Header header        # Header timestamp should be acquisition time of image\n\
                     # Header frame_id should be optical frame of camera\n\
                     # origin of frame should be optical center of camera\n\
                     # +x should point to the right in the image\n\
                     # +y should point down in the image\n\
                     # +z should point into to plane of the image\n\
\n\
# Camera resolution in pixels\n\
uint32 height\n\
uint32 width\n\
\n\
# Region of interest (subwindow of full camera resolution), if applicable\n\
RegionOfInterest roi\n\
\n\
##########################################\n\
# Internal parameters                    #\n\
# Used for warping to:                   #\n\
#  1. An undistorted image (just D and K)#\n\
#  2. A rectified image (D, K, R)        #\n\
# Users should not normally need these   #\n\
##########################################\n\
\n\
# Distortion parameters: k1, k2, t1, t2, k3\n\
# These model radial and tangential distortion of the camera.\n\
float64[5]  D # 5x1 vector\n\
\n\
# Intrinsic camera matrix for the raw (distorted) images\n\
# Projects 3D points in the camera coordinate frame to 2D pixel\n\
# coordinates using the focal lengths (fx, fy) and principal point\n\
# (cx, cy):\n\
#     [fx  0 cx]\n\
# K = [ 0 fy cy]\n\
#     [ 0  0  1]\n\
\n\
float64[9]  K # 3x3 row-major matrix\n\
\n\
\n\
# Rectification matrix (stereo cameras only)\n\
# A homography which takes an image to the ideal stereo image plane\n\
# so that epipolar lines in both stereo images are parallel.\n\
float64[9]  R # 3x3 row-major matrix\n\
\n\
######################################\n\
# Projection/camera matrix           #\n\
# This is a 3x4 projection matrix    #\n\
#   for going from 3D to 2D coords   #\n\
######################################\n\
\n\
# Projection/camera matrix\n\
# By convention, this matrix specifies the intrinsic (camera)\n\
#   matrix of the processed (rectified) image.\n\
# Upper 3x3 portion is the normal camera intrinsic matrix for\n\
#   the rectified image\n\
# Projects 3D points in the camera coordinate frame to 2D pixel\n\
# coordinates using the focal lengths (fx, fy) and principal point\n\
# (cx, cy):\n\
#              [fx  0 cx]\n\
# P[1:3,1:3] = [ 0 fy cy]\n\
#              [ 0  0  1]\n\
# For the right camera of a stereo pair, P[4,1] is the position\n\
#  of the right camera center in the left camera's frame, times\n\
#  the focal length fx.\n\
# \n\
# Given a 3D point q=[XYZ]^T in the left camera frame, the projection\n\
#  of the point onto the image is given by [uvw]^T = Pq, with x=u/w and y=v/w.\n\
#  This holds for both left and right images of a stereo pair.  \n\
#  For monocular cameras and the left image of a stereo pair, P[4,1] is always 0.\n\
\n\
float64[12] P # 3x4 row-major matrix\n\
\n\
================================================================================\n\
MSG: roslib/Header\n\
# Standard metadata for higher-level stamped data types.\n\
# This is generally used to communicate timestamped data \n\
# in a particular coordinate frame.\n\
# \n\
# sequence ID: consecutively increasing ID \n\
uint32 seq\n\
#Two-integer timestamp that is expressed as:\n\
# * stamp.secs: seconds (stamp_secs) since epoch\n\
# * stamp.nsecs: nanoseconds since stamp_secs\n\
# time-handling sugar is provided by the client library\n\
time stamp\n\
#Frame this data is associated with\n\
# 0: no frame\n\
# 1: global frame\n\
string frame_id\n\
\n\
================================================================================\n\
MSG: sensor_msgs/RegionOfInterest\n\
# This message is used to specify a region of interest within an image\n\
#\n\
# When used to specify the ROI setting of the camera when the image was taken,\n\
# the height and width fields should either match the height and width\n\
# fields for the associated image or be zeroes to indicate that the full image\n\
# was captured\n\
\n\
uint32 x_offset  #Leftmost pixel of the ROI (0 if the left edge of the image is included in the ROI)\n\
uint32 y_offset  #Topmost pixel of the ROI (0 if the top edge of the image is included in the ROI)\n\
uint32 height    #Height of ROI\n\
uint32 width     #Width of ROI\n\
\n\
"; }
public:
  ROSCPP_DEPRECATED static const std::string __s_getMessageDefinition() { return __s_getMessageDefinition_(); }

  ROSCPP_DEPRECATED const std::string __getMessageDefinition() const { return __s_getMessageDefinition_(); }

  ROSCPP_DEPRECATED virtual uint8_t *serialize(uint8_t *write_ptr, uint32_t seq) const
  {
    ros::serialization::OStream stream(write_ptr, 1000000000);
    ros::serialization::serialize(stream, header);
    ros::serialization::serialize(stream, height);
    ros::serialization::serialize(stream, width);
    ros::serialization::serialize(stream, roi);
    ros::serialization::serialize(stream, D);
    ros::serialization::serialize(stream, K);
    ros::serialization::serialize(stream, R);
    ros::serialization::serialize(stream, P);
    return stream.getData();
  }

  ROSCPP_DEPRECATED virtual uint8_t *deserialize(uint8_t *read_ptr)
  {
    ros::serialization::IStream stream(read_ptr, 1000000000);
    ros::serialization::deserialize(stream, header);
    ros::serialization::deserialize(stream, height);
    ros::serialization::deserialize(stream, width);
    ros::serialization::deserialize(stream, roi);
    ros::serialization::deserialize(stream, D);
    ros::serialization::deserialize(stream, K);
    ros::serialization::deserialize(stream, R);
    ros::serialization::deserialize(stream, P);
    return stream.getData();
  }

  ROSCPP_DEPRECATED virtual uint32_t serializationLength() const
  {
    uint32_t size = 0;
    size += ros::serialization::serializationLength(header);
    size += ros::serialization::serializationLength(height);
    size += ros::serialization::serializationLength(width);
    size += ros::serialization::serializationLength(roi);
    size += ros::serialization::serializationLength(D);
    size += ros::serialization::serializationLength(K);
    size += ros::serialization::serializationLength(R);
    size += ros::serialization::serializationLength(P);
    return size;
  }

  typedef boost::shared_ptr< ::sensor_msgs::CameraInfo_<ContainerAllocator> > Ptr;
  typedef boost::shared_ptr< ::sensor_msgs::CameraInfo_<ContainerAllocator>  const> ConstPtr;
}; // struct CameraInfo
typedef  ::sensor_msgs::CameraInfo_<std::allocator<void> > CameraInfo;

typedef boost::shared_ptr< ::sensor_msgs::CameraInfo> CameraInfoPtr;
typedef boost::shared_ptr< ::sensor_msgs::CameraInfo const> CameraInfoConstPtr;


template<typename ContainerAllocator>
std::ostream& operator<<(std::ostream& s, const  ::sensor_msgs::CameraInfo_<ContainerAllocator> & v)
{
  ros::message_operations::Printer< ::sensor_msgs::CameraInfo_<ContainerAllocator> >::stream(s, "", v);
  return s;}

} // namespace sensor_msgs

namespace ros
{
namespace message_traits
{
template<class ContainerAllocator>
struct MD5Sum< ::sensor_msgs::CameraInfo_<ContainerAllocator> > {
  static const char* value() 
  {
    return "1b5cf7f984c229b6141ceb3a955aa18f";
  }

  static const char* value(const  ::sensor_msgs::CameraInfo_<ContainerAllocator> &) { return value(); } 
  static const uint64_t static_value1 = 0x1b5cf7f984c229b6ULL;
  static const uint64_t static_value2 = 0x141ceb3a955aa18fULL;
};

template<class ContainerAllocator>
struct DataType< ::sensor_msgs::CameraInfo_<ContainerAllocator> > {
  static const char* value() 
  {
    return "sensor_msgs/CameraInfo";
  }

  static const char* value(const  ::sensor_msgs::CameraInfo_<ContainerAllocator> &) { return value(); } 
};

template<class ContainerAllocator>
struct Definition< ::sensor_msgs::CameraInfo_<ContainerAllocator> > {
  static const char* value() 
  {
    return "# This message defines meta information for a camera. It should be in a\n\
# camera namespace and accompanied by up to 5 image topics named:\n\
# \n\
# image_raw, image, image_color, image_rect, and image_rect_color\n\
#\n\
# The meaning of the camera parameters are described in detail at\n\
# http://pr.willowgarage.com/wiki/camera_calibration.\n\
\n\
##########################\n\
# Image acquisition info #\n\
##########################\n\
\n\
# Time of image acquisition, camera coordinate frame ID\n\
Header header        # Header timestamp should be acquisition time of image\n\
                     # Header frame_id should be optical frame of camera\n\
                     # origin of frame should be optical center of camera\n\
                     # +x should point to the right in the image\n\
                     # +y should point down in the image\n\
                     # +z should point into to plane of the image\n\
\n\
# Camera resolution in pixels\n\
uint32 height\n\
uint32 width\n\
\n\
# Region of interest (subwindow of full camera resolution), if applicable\n\
RegionOfInterest roi\n\
\n\
##########################################\n\
# Internal parameters                    #\n\
# Used for warping to:                   #\n\
#  1. An undistorted image (just D and K)#\n\
#  2. A rectified image (D, K, R)        #\n\
# Users should not normally need these   #\n\
##########################################\n\
\n\
# Distortion parameters: k1, k2, t1, t2, k3\n\
# These model radial and tangential distortion of the camera.\n\
float64[5]  D # 5x1 vector\n\
\n\
# Intrinsic camera matrix for the raw (distorted) images\n\
# Projects 3D points in the camera coordinate frame to 2D pixel\n\
# coordinates using the focal lengths (fx, fy) and principal point\n\
# (cx, cy):\n\
#     [fx  0 cx]\n\
# K = [ 0 fy cy]\n\
#     [ 0  0  1]\n\
\n\
float64[9]  K # 3x3 row-major matrix\n\
\n\
\n\
# Rectification matrix (stereo cameras only)\n\
# A homography which takes an image to the ideal stereo image plane\n\
# so that epipolar lines in both stereo images are parallel.\n\
float64[9]  R # 3x3 row-major matrix\n\
\n\
######################################\n\
# Projection/camera matrix           #\n\
# This is a 3x4 projection matrix    #\n\
#   for going from 3D to 2D coords   #\n\
######################################\n\
\n\
# Projection/camera matrix\n\
# By convention, this matrix specifies the intrinsic (camera)\n\
#   matrix of the processed (rectified) image.\n\
# Upper 3x3 portion is the normal camera intrinsic matrix for\n\
#   the rectified image\n\
# Projects 3D points in the camera coordinate frame to 2D pixel\n\
# coordinates using the focal lengths (fx, fy) and principal point\n\
# (cx, cy):\n\
#              [fx  0 cx]\n\
# P[1:3,1:3] = [ 0 fy cy]\n\
#              [ 0  0  1]\n\
# For the right camera of a stereo pair, P[4,1] is the position\n\
#  of the right camera center in the left camera's frame, times\n\
#  the focal length fx.\n\
# \n\
# Given a 3D point q=[XYZ]^T in the left camera frame, the projection\n\
#  of the point onto the image is given by [uvw]^T = Pq, with x=u/w and y=v/w.\n\
#  This holds for both left and right images of a stereo pair.  \n\
#  For monocular cameras and the left image of a stereo pair, P[4,1] is always 0.\n\
\n\
float64[12] P # 3x4 row-major matrix\n\
\n\
================================================================================\n\
MSG: roslib/Header\n\
# Standard metadata for higher-level stamped data types.\n\
# This is generally used to communicate timestamped data \n\
# in a particular coordinate frame.\n\
# \n\
# sequence ID: consecutively increasing ID \n\
uint32 seq\n\
#Two-integer timestamp that is expressed as:\n\
# * stamp.secs: seconds (stamp_secs) since epoch\n\
# * stamp.nsecs: nanoseconds since stamp_secs\n\
# time-handling sugar is provided by the client library\n\
time stamp\n\
#Frame this data is associated with\n\
# 0: no frame\n\
# 1: global frame\n\
string frame_id\n\
\n\
================================================================================\n\
MSG: sensor_msgs/RegionOfInterest\n\
# This message is used to specify a region of interest within an image\n\
#\n\
# When used to specify the ROI setting of the camera when the image was taken,\n\
# the height and width fields should either match the height and width\n\
# fields for the associated image or be zeroes to indicate that the full image\n\
# was captured\n\
\n\
uint32 x_offset  #Leftmost pixel of the ROI (0 if the left edge of the image is included in the ROI)\n\
uint32 y_offset  #Topmost pixel of the ROI (0 if the top edge of the image is included in the ROI)\n\
uint32 height    #Height of ROI\n\
uint32 width     #Width of ROI\n\
\n\
";
  }

  static const char* value(const  ::sensor_msgs::CameraInfo_<ContainerAllocator> &) { return value(); } 
};

template<class ContainerAllocator> struct HasHeader< ::sensor_msgs::CameraInfo_<ContainerAllocator> > : public TrueType {};
} // namespace message_traits
} // namespace ros

namespace ros
{
namespace serialization
{

template<class ContainerAllocator> struct Serializer< ::sensor_msgs::CameraInfo_<ContainerAllocator> >
{
  template<typename Stream, typename T> inline static void allInOne(Stream& stream, T m)
  {
    stream.next(m.header);
    stream.next(m.height);
    stream.next(m.width);
    stream.next(m.roi);
    stream.next(m.D);
    stream.next(m.K);
    stream.next(m.R);
    stream.next(m.P);
  }

  ROS_DECLARE_ALLINONE_SERIALIZER;
}; // struct CameraInfo_
} // namespace serialization
} // namespace ros

namespace ros
{
namespace message_operations
{

template<class ContainerAllocator>
struct Printer< ::sensor_msgs::CameraInfo_<ContainerAllocator> >
{
  template<typename Stream> static void stream(Stream& s, const std::string& indent, const  ::sensor_msgs::CameraInfo_<ContainerAllocator> & v) 
  {
    s << indent << "header: ";
s << std::endl;
    Printer< ::roslib::Header_<ContainerAllocator> >::stream(s, indent + "  ", v.header);
    s << indent << "height: ";
    Printer<uint32_t>::stream(s, indent + "  ", v.height);
    s << indent << "width: ";
    Printer<uint32_t>::stream(s, indent + "  ", v.width);
    s << indent << "roi: ";
s << std::endl;
    Printer< ::sensor_msgs::RegionOfInterest_<ContainerAllocator> >::stream(s, indent + "  ", v.roi);
    s << indent << "D[]" << std::endl;
    for (size_t i = 0; i < v.D.size(); ++i)
    {
      s << indent << "  D[" << i << "]: ";
      Printer<double>::stream(s, indent + "  ", v.D[i]);
    }
    s << indent << "K[]" << std::endl;
    for (size_t i = 0; i < v.K.size(); ++i)
    {
      s << indent << "  K[" << i << "]: ";
      Printer<double>::stream(s, indent + "  ", v.K[i]);
    }
    s << indent << "R[]" << std::endl;
    for (size_t i = 0; i < v.R.size(); ++i)
    {
      s << indent << "  R[" << i << "]: ";
      Printer<double>::stream(s, indent + "  ", v.R[i]);
    }
    s << indent << "P[]" << std::endl;
    for (size_t i = 0; i < v.P.size(); ++i)
    {
      s << indent << "  P[" << i << "]: ";
      Printer<double>::stream(s, indent + "  ", v.P[i]);
    }
  }
};


} // namespace message_operations
} // namespace ros

#endif // SENSOR_MSGS_MESSAGE_CAMERAINFO_H

